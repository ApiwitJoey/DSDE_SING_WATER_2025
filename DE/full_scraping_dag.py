from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime, timedelta
import re

# ==========================================
# âš™ï¸ Configuration
# ==========================================
default_args = {
    'owner': 'data_team',
    'retries': 2,
    'retry_delay': timedelta(minutes=1),
    'email_on_failure': False,
}

def sanitize_task_id(name):
    # à¹à¸›à¸¥à¸‡à¸—à¸¸à¸à¸•à¸±à¸§à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ A-Z a-z 0-9 _ - . à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ _
    return re.sub(r'[^A-Za-z0-9._-]', '_', name)

# Mapping: (à¸Šà¸·à¹ˆà¸­à¹„à¸—à¸¢à¸ªà¹ˆà¸‡à¹ƒà¸«à¹‰ Python, à¸Šà¸·à¹ˆà¸­à¸­à¸±à¸‡à¸à¸¤à¸©à¸•à¸±à¹‰à¸‡à¸Šà¸·à¹ˆà¸­ Task)
DISTRICTS_MAP = [
    ('à¸ˆà¸•à¸¸à¸ˆà¸±à¸à¸£', 'Chatuchak'),
    ('à¸›à¸£à¸°à¹€à¸§à¸¨', 'Prawet'),
    ('à¸§à¸±à¸’à¸™à¸²', 'Watthana'),
    ('à¸šà¸²à¸‡à¸à¸°à¸›à¸´', 'Bang_Kapi'),
    ('à¸„à¸¥à¸­à¸‡à¹€à¸•à¸¢', 'Khlong_Toei'),
    ('à¸šà¸²à¸‡à¹à¸„', 'Bang_Khae'),
    ('à¸›à¸—à¸¸à¸¡à¸§à¸±à¸™', 'Pathum_Wan'),
    ('à¸šà¸²à¸‡à¹€à¸‚à¸™', 'Bang_Khen')
]

# ==========================================
# ðŸŒŠ DAG Definition
# ==========================================
with DAG(
    'parallel_condo_pipeline',
    default_args=default_args,
    description='Link -> Scrape (Parallel by District) -> Cleansing',
    schedule=None,  
    start_date=datetime(2023, 12, 1),
    catchup=False,
    max_active_tasks=6, # à¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™à¸«à¸™à¹ˆà¸­à¸¢à¹€à¸žà¸£à¸²à¸°à¹€à¸£à¸²à¸¡à¸µ Task à¸¢à¹ˆà¸­à¸¢à¹€à¸¢à¸­à¸°à¸‚à¸¶à¹‰à¸™ (Link+Scrape)
) as dag:

    # --------------------------------------------------------
    # Step 3: Cleansing (à¸£à¸­à¸£à¸±à¸šà¸‡à¸²à¸™à¸ˆà¸²à¸à¸—à¸¸à¸à¹€à¸‚à¸•)
    # --------------------------------------------------------
    t3_clean = BashOperator(
        task_id='clean_and_merge_data',
        # à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹€à¸›à¹‡à¸™ condo_cleansing.py à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸‚à¸­
        bash_command='python /opt/airflow/dags/scripts/condo_cleansing.py',
        trigger_rule='all_done' # à¸£à¸±à¸™à¹€à¸ªà¸¡à¸­ à¹à¸¡à¹‰à¸šà¸²à¸‡à¹€à¸‚à¸•à¸ˆà¸°à¸žà¸±à¸‡
    )

    # --------------------------------------------------------
    # Loop à¸ªà¸£à¹‰à¸²à¸‡ Pipeline à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¹€à¸‚à¸• (Step 1 -> Step 2)
    # --------------------------------------------------------
    for district_th, district_en in DISTRICTS_MAP:
        
        clean_en = sanitize_task_id(district_en)

        # Step 1: à¸«à¸² Link (à¹€à¸‰à¸žà¸²à¸°à¹€à¸‚à¸•à¸™à¸µà¹‰)
        t1_link = BashOperator(
            task_id=f'get_links_{clean_en}',
            # à¸ªà¹ˆà¸‡à¸Šà¸·à¹ˆà¸­à¹€à¸‚à¸•à¹„à¸›à¹ƒà¸«à¹‰ condo_link.py
            bash_command=f'python /opt/airflow/dags/scripts/condo_link.py "{district_th}"',
        )

        # Step 2: Scrape Details (à¹€à¸‰à¸žà¸²à¸°à¹€à¸‚à¸•à¸™à¸µà¹‰)
        t2_scrape = BashOperator(
            task_id=f'scrape_{clean_en}',
            # à¸ªà¹ˆà¸‡à¸Šà¸·à¹ˆà¸­à¹€à¸‚à¸•à¹„à¸›à¹ƒà¸«à¹‰ condo_scraping.py
            bash_command=f'python /opt/airflow/dags/scripts/condo_scraping.py "{district_th}"',
        )

        # ðŸ”— à¸œà¸¹à¸à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ (Linear à¹€à¸‰à¸žà¸²à¸°à¹€à¸‚à¸•)
        # 1. à¸«à¸² Link à¹€à¸‚à¸•à¸™à¸µà¹‰à¹€à¸ªà¸£à¹‡à¸ˆ -> 2. à¹„à¸› Scrape à¹€à¸‚à¸•à¸™à¸µà¹‰à¸•à¹ˆà¸­ -> 3. à¸–à¹‰à¸²à¹€à¸ªà¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§à¹„à¸›à¸£à¸­ Clean à¸£à¸§à¸¡
        t1_link >> t2_scrape >> t3_clean